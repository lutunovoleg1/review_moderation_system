{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Обученная модель с HuggingFace\n",
        "Из-за ограниченности вычислительных ресурсов попробую взять уже обученную на датасете RuSentiment модель BERT с HuggingFace.\n",
        "Ссылка на модель - https://huggingface.co/blanchefort/rubert-base-cased-sentiment-rusentiment"
      ],
      "metadata": {
        "id": "zDxn_zsEypti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    BertTokenizerFast,\n",
        "    AutoModelForSequenceClassification,\n",
        "    pipeline\n",
        ")\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "2u2nAvUzzoSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузка обученной модели\n",
        "model_name = 'blanchefort/rubert-base-cased-sentiment-rusentiment'\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True)\n",
        "\n",
        "print(f\"Модель загружена! Параметров: {model.num_parameters():,}\")\n",
        "print(f\"Устройство: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkML4ZV1zoPT",
        "outputId": "bec86105-3d8c-44f6-88b9-d2fd0ff793e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель загружена! Параметров: 177,855,747\n",
            "Устройство: CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# соответствие меток\n",
        "print(model.config.id2label)\n",
        "print(model.config.label2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybcxqvqHzoM3",
        "outputId": "ea59190c-7006-4518-b9e7-43b49ceb1c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'NEUTRAL', 1: 'POSITIVE', 2: 'NEGATIVE'}\n",
            "{'NEUTRAL': 0, 'POSITIVE': 1, 'NEGATIVE': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка только тестовой выборки\n",
        "df_test = load_dataset(\"MonoHime/ru_sentiment_dataset\", split=\"validation\")\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRGhpR5kzoIR",
        "outputId": "7ce12b86-21ed-4710-d93f-6a0e957d4188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'text', 'sentiment'],\n",
              "    num_rows: 21098\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device).eval()"
      ],
      "metadata": {
        "id": "5xvPmOK2Q4DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(texts: list[str]) -> np.array:\n",
        "    inputs = tokenizer(texts, max_length=256, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted\n",
        "\n",
        "def predict_by_batch(texts, batch_size):\n",
        "  all_preds = []\n",
        "\n",
        "  for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
        "    batch_texts = texts[i:i + batch_size]\n",
        "    preds = predict(batch_texts)\n",
        "    all_preds.extend(preds)\n",
        "\n",
        "  return np.array(all_preds)"
      ],
      "metadata": {
        "id": "UmfOaO6t120J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.array(df_test[\"sentiment\"])\n",
        "y_test_pred = predict_by_batch(list(df_test['text']), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw8NqLcj6_Db",
        "outputId": "e20c53f2-9ca3-455c-ec1c-df293abad688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 660/660 [05:22<00:00,  2.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueGgHH0bBxlE",
        "outputId": "e24e6a25-62a5-4011-a31d-d4c93a7b3caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6086358896577875"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYgq-nnO-K1n",
        "outputId": "88c6ebdf-6c0d-4478-cee4-faed933ed3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.56      0.49      5560\n",
            "           1       0.74      0.67      0.71     10026\n",
            "           2       0.63      0.54      0.58      5512\n",
            "\n",
            "    accuracy                           0.61     21098\n",
            "   macro avg       0.60      0.59      0.59     21098\n",
            "weighted avg       0.63      0.61      0.61     21098\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество достаточно низкое, попробуем дообучить свою модель BERT."
      ],
      "metadata": {
        "id": "Ehy3wUFMCJLu"
      }
    }
  ]
}